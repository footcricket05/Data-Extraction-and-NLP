{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "ilfWw8m8CwAB"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from newspaper import Article\n",
        "import syllables"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the output dataframe\n",
        "output_data = pd.DataFrame(columns=[\"URL_ID\", \"URL\", \"POSITIVE SCORE\", \"NEGATIVE SCORE\", \"POLARITY SCORE\", \"SUBJECTIVITY SCORE\",\n",
        "                                    \"AVG SENTENCE LENGTH\", \"PERCENTAGE OF COMPLEX WORDS\", \"FOG INDEX\",\n",
        "                                    \"AVG NUMBER OF WORDS PER SENTENCE\", \"COMPLEX WORD COUNT\", \"WORD COUNT\",\n",
        "                                    \"SYLLABLE PER WORD\", \"PERSONAL PRONOUNS\", \"AVG WORD LENGTH\"])\n"
      ],
      "metadata": {
        "id": "kRicVoOfC01V"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read URLs from Excel file\n",
        "input_data = pd.read_excel('/content/Input.xlsx')"
      ],
      "metadata": {
        "id": "5HKIiZ8JC6TS"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "tOJ--YZpDLyT"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the URLs\n",
        "for i, row in input_data.iterrows():\n",
        "    url = row['URL']\n",
        "    \n",
        "    try:\n",
        "        # Extract article text\n",
        "        article = Article(url)\n",
        "        article.download()\n",
        "        article.parse()\n",
        "        article_text = article.text\n",
        "        \n",
        "        # Perform sentiment analysis\n",
        "        sentiment_scores = sia.polarity_scores(article_text)\n",
        "        \n",
        "        # Compute other variables\n",
        "        word_count = len(nltk.word_tokenize(article_text))\n",
        "        sentence_count = len(nltk.sent_tokenize(article_text))\n",
        "        avg_sentence_length = word_count / sentence_count\n",
        "        \n",
        "        # Compute percentage of complex words (example, using a threshold of word length > 5)\n",
        "        words = nltk.word_tokenize(article_text)\n",
        "        complex_word_count = sum(1 for word in words if len(word) > 5)\n",
        "        percentage_complex_words = (complex_word_count / word_count) * 100\n",
        "        \n",
        "        # Compute other variables and scores\n",
        "        fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
        "        avg_words_per_sentence = word_count / sentence_count\n",
        "        syllables_per_word = sum(syllables.estimate(word) for word in words) / word_count\n",
        "        personal_pronouns = sum(1 for word in words if word.lower() in [\"i\", \"me\", \"my\", \"mine\"])\n",
        "        avg_word_length = sum(len(word) for word in words) / word_count\n",
        "        \n",
        "        # Create a new row for the output dataframe\n",
        "        output_row = {\n",
        "            \"URL_ID\": i+1,\n",
        "            \"URL\": url,\n",
        "            \"POSITIVE SCORE\": sentiment_scores[\"pos\"],\n",
        "            \"NEGATIVE SCORE\": sentiment_scores[\"neg\"],\n",
        "            \"POLARITY SCORE\": sentiment_scores[\"compound\"],\n",
        "            \"SUBJECTIVITY SCORE\": sentiment_scores[\"compound\"],\n",
        "            \"AVG SENTENCE LENGTH\": avg_sentence_length,\n",
        "            \"PERCENTAGE OF COMPLEX WORDS\": percentage_complex_words,\n",
        "            \"FOG INDEX\": fog_index,\n",
        "            \"AVG NUMBER OF WORDS PER SENTENCE\": avg_words_per_sentence,\n",
        "            \"COMPLEX WORD COUNT\": complex_word_count,\n",
        "            \"WORD COUNT\": word_count,\n",
        "            \"SYLLABLE PER WORD\": syllables_per_word,\n",
        "            \"PERSONAL PRONOUNS\": personal_pronouns,\n",
        "            \"AVG WORD LENGTH\": avg_word_length\n",
        "        }\n",
        "        \n",
        "        # Append the row to the output dataframe\n",
        "        output_data = pd.concat([output_data, pd.DataFrame([output_row])], ignore_index=True)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error processing URL: {url}\")\n",
        "        print(e)\n",
        "        continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d_ebV7oDwWS",
        "outputId": "b0ce4a2a-d2c3-46d0-df5c-42858d90ff6b"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing URL: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
            "Article `download()` failed with 404 Client Error: Not Found for url: https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/ on URL https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
            "Error processing URL: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
            "Article `download()` failed with 404 Client Error: Not Found for url: https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/ on URL https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
            "Error processing URL: https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology/\n",
            "Article `download()` failed with 404 Client Error: Not Found for url: https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology/ on URL https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the output dataframe as a CSV file\n",
        "output_file_path = \"/content/output.csv\"\n",
        "output_data.to_csv(output_file_path, index=False)\n",
        "print(\"Output CSV file saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYMLZEmTKce4",
        "outputId": "6934bbc2-8e7a-485b-ad07-29e9e83160a8"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output CSV file saved successfully.\n"
          ]
        }
      ]
    }
  ]
}